
        <image>
        <path>
        outputs/images/chapter_2/page_6_0.jpg
        </path>
        <description>
        A circular chart with various colored lines and markers, each representing a different entity or category. The center has labels such as 'Clarity', 'Effectiveness', 'Novelty', etc., while the outer ring is labeled from 700 to 1200 in increments of 100.
        </description>
        </image>
        

        <image>
        <path>
        outputs/images/chapter_2/page_6_1.jpg
        </path>
        <description>
        A circular chart with various colored lines and points, representing different categories such as Clarity, Effectiveness, Feasibility, Novelty, Significance, AI-Scientist, ResearchAgent, GPT-Researcher, Real Paper, CoI Agent (ours), RAG. The center of the circle has a label 'Average' with various numerical values around it indicating scores for each category.
        </description>
        </image>
        

            <caption>
            # Figure 3: Evaluation results of idea generation with LLM as a judge.

Figure 3: Evaluation results of idea generation with LLM as a judge.
            </caption>
            

            <caption>
            # Figure 4: Evaluation results of idea generation with human as judges.

Figure 4: Evaluation results of idea generation with human as judges.
            </caption>
            

            <text>
            between automatic methods and Real Paper is expected, as Real Paper ideas undergo extensive experimental validation. Additionally, AlI-Scientist’s performance is especially low, likely due to its original design, which focuses on generating full papers from executable code. When given only a research topic, its simplistic idea generation framework limits its ability to produce novel and feasible ideas.
            </text>
            

            <text>
            Table 1: Agreement between the human and GPT-4o judges in all evaluated dimensions.
            </text>
            

                <table>
                
<headers>
    ['Novelty', 'Significance', 'Clarity', 'Feasibility', 'Effectiveness', 'Average']
</headers>
<rows>
        <row>['Agreement', '66.5% % 71.0% % 76.3% % 70.2% % 71.0% % 70.8%']</row>
</rows>
        
                </table>
                

            <caption>
            **Human-Model Agreements of Idea Arena.** To assess the reliability of our model-based evaluation within Idea Arena, we analyze the agreements between the preferences of the human judges and the LLM judges. We follow [Zheng et al.] (2024) to compute the agreement, which is defined as the probability that two judges agree on the winner of one specific arena match. Figure 5 shows the pairwise agreement between humans and several state-of-the-art LLMs, including GPT-40, Gemini-1.5-Pro-Exp-0827', and Claude-3.5-Sonnef*. We observe an average agreement of 70.8

Additionally, we present the agreement on individual criteria between GPT-40 and human evaluators in Table I. The results indicate a consistently high level of agreement across all assessed criteria.
            </caption>
            

        <image>
        <path>
        outputs/images/chapter_2/page_6_8.jpg
        </path>
        <description>
        A heatmap showing various percentages for different models and humans. The rows represent Human, GT-40, GPT-4o, Claude-3.5, Gemini-1.5-pro, and Gemini-1.5-pro (pro). The columns are labeled as Human, GT-40, GPT-4o, Claude-3.5, Gemini-1.5-pro, and Gemini-1.5-pro (pro). Each cell contains a percentage value ranging from -1 to 1.
        </description>
        </image>
        

            <title>
            4.2 ABLATION STUDIES FOR IDEA GENERATION
            </title>
            

            <text>
            We conduct an ablation study to assess the contributions of each component of the Col Agent to idea generation quality. The following variants are examined: 1) — Col: Excludes the Col construction stage, directly using all retrieved literature without progressive relation mining. 2) — Future Trend:
            </text>
            

                <table>
                
<headers>
    ['7', '8']
</headers>
<rows>
        <row>['https://ai.google.dev/gemini-api/docs/models/experimental-models', 'https://www.anthropic.com/news/claudie-3-5-sonnet']</row>
</rows>
        
                </table>
                
