
            <title>
            Prim
Preprint
            </title>
            

        <image>
        <path>
        outputs/images/chapter_2/page_1_1.jpg
        </path>
        <description>
        <p>Enhancing Large Language Model Problem-Solving-capability</p>
        </description>
        </image>
        

            <caption>
            Figure 1: Comparison between the vanilla retrieval augmented generation (MAG) research agent and our Chain-of-Ideas agent on the idea generation task.
            </caption>
            

            <text>
            [et al.] (2024) have validated this hypothesis, highlighting its substantial potential to expedite the discovery of novel concepts and uncharted research avenues.
            </text>
            

            <text>
            Existing methods seek to address two key challenges to improve the quality of generated ideas: curating pertinent literature for LLMs to gain inspiration and ensuring the novelty of generated ideas. To address the first challenge, previous research enhances traditional academic retrieval systems, which typically depend on textual similarity, with academic knowledge graphs (Baek et al. [2024], Wang et al. [2023]). For the second challenge, existing approaches either apply predefined criteria such as novelty to guide the idea generation process (Baek et al. [2024]) or iteratively refine ideas until they demonstrate low embedding similarities with existing papers (Wang et al. [2023]).
            </text>
            

            <text>
            However, in existing attempts, LLMs are presented with an extensive volume of research literature when asked to generate ideas. This makes LLMs vulnerable to the influence of less relevant works, potentially resulting in ideas that lack logical coherence and technological innovation. As shown in the upper part of Figure[1], the LLM borrows from Graph[1] (Tang et al., 2024) and applies it into the GoGT framework (Bess et al., 2024). To capture the most important role in the theoretical development, we need to investigate the relationship between the two methods. To capture the most important role in the theoretical development, it is often necessary to trace the evolution of a research field by analyzing its progression from foundational works to the most recent advancements. This comprehensive perspective provides valuable insights into the key factors driving developments within the domain. Such an understanding enables researchers to critically assess the limitations of earlier studies while identifying emerging trends. Therefore, they are better grounded in devising innovative and impactful research ideas.
            </text>
            

            <text>
            Motivated by the human practices in conducting research, we introduce a novel Chain-of-Ideas (Col) agent framework to address the previously identified logical inconsistencies in the ideation processes of LLMs. As shown in the bottom part of Figure[I] Col agent aims to provide a clear landscape of current research topics by systematically selecting and organizing the relevant papers and their ideas in a chain structure. Col agent offers several distinctive advantages: Firstly, it minimizes the risk of interference from less relevant literature via carefully selecting papers (i.e., from CoT to GoT). Second, LLMs are demonstrated with human practice to craft a novel idea. For example, SC (Wang et al.||2022) emerges as a novel idea derived from CoT. This can be viewed as a form of few-shot prompting strategy, which has been proven to enhance the overall LLM’s generation capability 2020). Third, Col exemplifies a global progression in research development. As a result, LLMs can gain a deep understanding of the motivations behind these developmental trends, facilitating the identification of promising future research directions.
            </text>
            

            <text>
            Specifically, Col agent first retrieves an anchor paper of the given research topic. Instead of indiscriminately aggregating all papers within the citation network of the anchor, as done in (Baek et al., 2024), we construct the Col by selecting relevant and important literature from both the anchor’s references and its subsequent works, thereby extending the chain backward and forward from the
            </text>
            
